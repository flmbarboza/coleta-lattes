import io
import re
import time
import requests
import pandas as pd
import streamlit as st
import plotly.express as px
from PyPDF2 import PdfReader
from rapidfuzz import fuzz

# ---------------------------
# Configura√ß√£o Streamlit
# ---------------------------
st.set_page_config(page_title="Lattes ‚Üí Artigos ‚Üí Gr√°ficos", layout="wide")
st.title("üìö Lattes (PDF) ‚Üí Artigos em Peri√≥dicos ‚Üí Confirma√ß√£o ‚Üí Gr√°ficos")

# ---------------------------
# PDF ‚Üí texto
# ---------------------------
def pdf_to_text(file_bytes: bytes) -> str:
    reader = PdfReader(io.BytesIO(file_bytes))
    txt = []
    for p in reader.pages:
        txt.append(p.extract_text() or "")
    return "\n".join(txt)

# ---------------------------
# Recorta a se√ß√£o de Artigos completos em peri√≥dicos
# ---------------------------
def slice_journal_section(text: str) -> str:
    clean = re.sub(r"[ \t]+", " ", text)
    clean = re.sub(r"\n{2,}", "\n", clean)

    patterns_start = [
        r"Artigos completos publicados em peri√≥dicos",
        r"Artigos publicados em peri√≥dicos",
        r"Artigos completos em peri√≥dicos",
    ]
    patterns_end = [
        r"Trabalhos completos publicados em anais",
        r"Livros publicados",
        r"Cap√≠tulos de livros",
        r"Textos em jornais",
        r"Produ√ß√£o t√©cnica",
        r"Demais tipos de produ√ß√£o bibliogr√°fica",
    ]

    start = None
    for ps in patterns_start:
        m = re.search(ps, clean, flags=re.IGNORECASE)
        if m:
            start = m.start()
            break

    if start is None:
        return ""

    sub = clean[start:]
    end = None
    for pe in patterns_end:
        m = re.search(pe, sub, flags=re.IGNORECASE)
        if m:
            end = m.start()
            break

    if end is not None:
        sub = sub[:end]

    # remove o cabe√ßalho
    sub = re.sub(
        r"^.*?peri√≥dicos\s*\n", "", sub, flags=re.IGNORECASE | re.DOTALL
    )
    return sub.strip()

# ---------------------------
# Heur√≠stica para extrair artigos
# ---------------------------
def extract_articles_heuristic(section: str) -> pd.DataFrame:
    if not section:
        return pd.DataFrame(columns=["ano", "titulo", "doi"])

    # Divide por itens numerados (1., 2., 3., etc.)
    items = re.split(r"\n(?=\d+\.)", section)
    doi_regex = r"\b10\.\d{4,9}/[-._;()/:A-Z0-9]+\b"

    rows = []

    for it in items:
        it = it.strip()
        if len(it) < 30:
            continue

        # captura DOI
        mdoi = re.search(doi_regex, it, flags=re.IGNORECASE)
        doi = mdoi.group(0).rstrip(" .;,") if mdoi else ""

        # captura ano (√∫ltimo ano do item)
        years = re.findall(r"\b(19\d{2}|20\d{2})\b", it)
        ano = int(years[-1]) if years else None

        # tenta pegar t√≠tulo
        parts = [p.strip() for p in it.split(".") if p.strip()]
        if len(parts) >= 2:
            titulo = parts[1]
        else:
            titulo = re.sub(r"^\d+\.\s*", "", it.split("\n")[0]).strip()

        rows.append({"ano": ano, "titulo": titulo, "doi": doi})

    df = pd.DataFrame(rows)
    if not df.empty:
        df["titulo"] = (
            df["titulo"]
            .astype(str)
            .str.replace(r"\s+", " ", regex=True)
            .str.strip()
        )
        df["doi"] = df["doi"].fillna("").str.strip()

    return df

# ---------------------------
# OpenAlex: obter cited_by_count por DOI
# ---------------------------
OPENALEX_BASE = "https://api.openalex.org"

def openalex_work_by_doi(doi: str, api_key: str):
    """
    Recupera o 'Work' do OpenAlex via DOI:
    /works/https://doi.org/<DOI>
    """
    url = f"{OPENALEX_BASE}/works/https://doi.org/{doi}"
    r = requests.get(url, params={"api_key": api_key}, timeout=20)
    if r.status_code == 200:
        return r.json()
    return None

def add_citations(df: pd.DataFrame, api_key: str, progress_cb=None) -> pd.DataFrame:
    if df.empty:
        df["citacoes"] = []
        return df

    citations = []
    for i, row in df.iterrows():
        doi = (row.get("doi") or "").strip()
        cited = None

        if doi:
            try:
                wk = openalex_work_by_doi(doi, api_key)
                if wk:
                    cited = wk.get("cited_by_count", None)
            except Exception:
                cited = None

        citations.append(cited)
        if progress_cb:
            progress_cb(i + 1, len(df))
        time.sleep(0.10)

    out = df.copy()
    out["citacoes"] = citations
    return out

# ---------------------------
# UI
# ---------------------------

if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "assistant",
            "content": "Ol√°! Envie o PDF do Lattes e eu extraio os artigos publicados em peri√≥dicos para confirmar e gerar gr√°ficos."
        }
    ]

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

uploaded = st.file_uploader("üìÑ PDF do Lattes", type=["pdf"])

if uploaded:
    st.session_state.messages.append(
        {"role": "user", "content": f"Enviei o arquivo: **{uploaded.name}**"}
    )
    with st.chat_message("user"):
        st.markdown(f"Enviei o arquivo: **{uploaded.name}**")

    file_bytes = uploaded.read()

    with st.chat_message("assistant"):
        st.markdown("Lendo PDF e extraindo a se√ß√£o de *Artigos completos publicados em peri√≥dicos*‚Ä¶")

    text = pdf_to_text(file_bytes)
    section = slice_journal_section(text)

    if not section:
        st.error("N√£o encontrei a se√ß√£o de artigos. Se for PDF escaneado, ser√° necess√°rio OCR.")
        st.stop()

    df = extract_articles_heuristic(section)

    if df.empty:
        st.error("N√£o consegui extrair artigos. O PDF pode estar com formata√ß√£o incomum.")
        st.stop()

    st.success(f"Encontrei **{len(df)}** artigos. Confirme/edite abaixo:")

    df_edit = st.data_editor(
        df[["ano", "titulo", "doi"]],
        num_rows="dynamic",
        use_container_width=True
    )

    st.subheader("Cita√ß√µes via OpenAlex + gr√°ficos")
    fetch_cit = st.checkbox("Buscar cita√ß√µes no OpenAlex (via DOI)", value=True)

    if st.button("Gerar gr√°ficos"):
        df_final = df_edit.copy()
        df_final["ano"] = pd.to_numeric(df_final["ano"], errors="coerce").astype("Int64")
        df_final["titulo"] = df_final["titulo"].astype(str).str.strip()
        df_final["doi"] = df_final["doi"].astype(str).str.strip()

        df_final = df_final[df_final["titulo"].str.len() > 3].reset_index(drop=True)

        if df_final.empty:
            st.error("Nada v√°lido ap√≥s a edi√ß√£o.")
            st.stop()

        # cita√ß√µes
        if fetch_cit:
            api_key = st.secrets.get("OPENALEX_API_KEY", "")
            if not api_key:
                st.error("Configure a OPENALEX_API_KEY em Secrets no Streamlit Cloud.")
                st.stop()

            prog = st.progress(0)
            status = st.empty()

            def progress_cb(done, total):
                prog.progress(int((done / total) * 100))
                status.text(f"{done}/{total} artigos consultados‚Ä¶")

            df_final = add_citations(df_final, api_key, progress_cb)
            status.text("Consulta conclu√≠da.")
        else:
            df_final["citacoes"] = pd.NA

        # gr√°fico 1
        pub = (
            df_final.dropna(subset=["ano"])
            .groupby("ano", as_index=False)
            .size()
            .rename(columns={"size": "publicacoes"})
        )

        # gr√°fico 2
        cit = (
            df_final.dropna(subset=["ano", "citacoes"])
            .assign(citacoes=lambda x: pd.to_numeric(x["citacoes"], errors="coerce"))
            .dropna(subset=["citacoes"])
            .groupby("ano", as_index=False)["citacoes"]
            .mean()
            .rename(columns={"citacoes": "media_citacoes"})
        )

        c1, c2 = st.columns(2)

        with c1:
            st.markdown("### üìà Publica√ß√µes por ano")
            fig1 = px.bar(pub, x="ano", y="publicacoes", text="publicacoes")
            st.plotly_chart(fig1, use_container_width=True)

        with c2:
            st.markdown("### üìä M√©dia de cita√ß√µes por ano")
            if cit.empty:
                st.warning("N√£o h√° cita√ß√µes suficientes (provavelmente faltam DOIs).")
            else:
                fig2 = px.line(cit, x="ano", y="media_citacoes", markers=True)
                st.plotly_chart(fig2, use_container_width=True)

        st.markdown("### üîé Dados finais")
        st.dataframe(df_final, use_container_width=True)

        st.download_button(
            "Baixar CSV",
            df_final.to_csv(index=False).encode("utf-8"),
            file_name="artigos_lattes.csv",
            mime="text/csv",
        )
